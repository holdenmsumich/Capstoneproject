{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dbacfb9b-93ff-4ad0-9338-bfeab091fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6b5c4e6f-405e-4184-9a3a-9a1e2cc890f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\\\\b\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers (punctuation, curly brackets etc).\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    # replace the matched string with ' '\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(description, stop_words, normalization):\n",
    "    \n",
    "    if normalization == 'lemmatize':\n",
    "        # tokenize and lemmatize text\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(w) for w in word_tokenize(description)]\n",
    "        \n",
    "    elif normalization == 'stem':\n",
    "        # tokenize and stem text\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(w) for w in word_tokenize(description)]\n",
    "    \n",
    "   # remove tokens length of 2 or below and make all lowercase and remove stop words\n",
    "    tokens = [w.lower() for w in tokens if (w.lower() not in stop_words) and (len(w) > 2) and(w.isalpha())]\n",
    "    \n",
    "    return tokens    \n",
    "    \n",
    "def process_query(query, normalization):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    return tokenizer(clean_text(query), stop_words, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e0849dc-8c8c-422c-9ea7-ca84b1a21225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code example taken from https://towardsdatascience.com/build-a-text-recommendation-system-with-python-e8b95d9f251c\n",
    "def retrieve_top_n(m, max_docs):\n",
    "    # return the sum on all tokens of cosinus for each sentence\n",
    "    if len(m.shape) > 1:\n",
    "        cos_sim = np.mean(m, axis=0) \n",
    "    else: \n",
    "        cos_sim = m\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \\\n",
    "    mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:max_docs]  \n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "983ba8f9-9039-4e22-9fe1-7c27f15b25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LsiTfidfRecommenderSystem:\n",
    "    def __init__(self, docs, num_concepts=100, alpha=1.0, beta=0.75, gamma=0.15):\n",
    "        self.alpha, self.beta, self.gamma = alpha, beta, gamma\n",
    "        \n",
    "        # create a doc-term matrix out of our doc collection\n",
    "        self.vec = TfidfVectorizer()\n",
    "        doc_term_mat = self.vec.fit_transform([\" \".join(docs[doc_id]) for doc_id in docs])\n",
    "        self.svd = TruncatedSVD(n_components=num_concepts, random_state=42)\n",
    "        result = self.svd.fit_transform(doc_term_mat)\n",
    "        \n",
    "        self.q_vecs = {}\n",
    "        \n",
    "        self.doc_vecs = result # document vectors in a matrix\n",
    "        \n",
    "    def retrieve_docs(self, query, max_docs=10, normalization='lemmatize'):\n",
    "        query = ' '.join(process_query(query, normalization))\n",
    "        \n",
    "        if query not in self.q_vecs:\n",
    "            q_vec = self.vec.transform([query])\n",
    "            lsi_transform = self.svd.transform(q_vec)\n",
    "            self.q_vecs[query] = lsi_transform\n",
    "        \n",
    "        ret_docs = {}\n",
    "        \n",
    "        mat = cosine_similarity(self.q_vecs[query], self.doc_vecs)\n",
    "        best_index = retrieve_top_n(mat, max_docs=max_docs)\n",
    "        \n",
    "        return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5f1b3a9-9d90-4818-aac4-9f7362ea0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'assets/processed_df.pkl')\n",
    "docs = dict(zip(df['naics'], df['lemmatized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83a7687d-a29b-40fd-862a-e72a58b54984",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LsiTfidfRecommenderSystem(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "059bfd3c-f9cc-4632-8bad-42e65d55a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = lsi_model.retrieve_docs('Home improvement store', normalization='lemmatize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93bd07f7-f216-4c1d-957d-7a8e7b79b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_titles = pd.read_excel('assets/6-digit_2017_Codes.xlsx')\n",
    "naics_titles['naics'] = naics_titles['naics'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30ad1713-25ff-459f-8d4c-5eb89f0ed17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(naics_titles, on='naics', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e46c0b9a-fa7c-41a4-97a2-80ab0525a1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>442299</td>\n",
       "      <td>All Other Home Furnishings Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>442291</td>\n",
       "      <td>Window Treatment Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>442210</td>\n",
       "      <td>Floor Covering Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>453998</td>\n",
       "      <td>All Other Miscellaneous Store Retailers (excep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>453991</td>\n",
       "      <td>Tobacco Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>453930</td>\n",
       "      <td>Manufactured (Mobile) Home Dealers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>453910</td>\n",
       "      <td>Pet and Pet Supplies Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>453920</td>\n",
       "      <td>Art Dealers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>453310</td>\n",
       "      <td>Used Merchandise Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>453220</td>\n",
       "      <td>Gift, Novelty, and Souvenir Stores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      naics                                              title\n",
       "578  442299                 All Other Home Furnishings Stores \n",
       "577  442291                           Window Treatment Stores \n",
       "576  442210                             Floor Covering Stores \n",
       "629  453998  All Other Miscellaneous Store Retailers (excep...\n",
       "628  453991                                    Tobacco Stores \n",
       "627  453930                Manufactured (Mobile) Home Dealers \n",
       "625  453910                       Pet and Pet Supplies Stores \n",
       "626  453920                                       Art Dealers \n",
       "624  453310                           Used Merchandise Stores \n",
       "623  453220                Gift, Novelty, and Souvenir Stores "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[best_index][['naics', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5241ca42-f449-4071-ac18-b97e4b5cd0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevant_naics = pd.read_pickle('assets/relevant_naics_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe55c649-9fe7-40b9-9b0f-f1836eb61540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>relevant_naics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home improvement store</td>\n",
       "      <td>[444110, 444120, 444130, 444190, 444210, 44422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diesel fuel supplier</td>\n",
       "      <td>[424710, 424720, 424110, 424120, 424130, 42421...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Church</td>\n",
       "      <td>[813110, 813211, 813212, 813219, 813311, 81331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farm</td>\n",
       "      <td>[115116, 115111, 115112, 115113, 115114, 11511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seed supplier</td>\n",
       "      <td>[424910, 424920, 424930, 424940, 424950, 42499...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    query                                     relevant_naics\n",
       "0  Home improvement store  [444110, 444120, 444130, 444190, 444210, 44422...\n",
       "1    Diesel fuel supplier  [424710, 424720, 424110, 424120, 424130, 42421...\n",
       "2                  Church  [813110, 813211, 813212, 813219, 813311, 81331...\n",
       "3                    Farm  [115116, 115111, 115112, 115113, 115114, 11511...\n",
       "4           Seed supplier  [424910, 424920, 424930, 424940, 424950, 42499..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_naics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e8e0d57-ab61-4acf-9b80-7489c685f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_docs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "609adb0e-9aa5-4322-81fe-e7a8aa943c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pre_rec_at_n(ret_docs, reljudges, n=-1):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall at n for each query in ret_docs\n",
    "    \"\"\"\n",
    "    \n",
    "    pre_at_n, rec_at_n = {}, {}\n",
    "    \n",
    "    for k, v in ret_docs.items():\n",
    "        if n > -1 and n <= len(ret_docs):\n",
    "            s1 = set(v[:n])\n",
    "        else:\n",
    "            s1 = set(v)\n",
    "        s2 = reljudges[k]\n",
    "        precision = len(s1.intersection(s2)) / len(s1)\n",
    "        recall = len(s1.intersection(s2)) / len(reljudges[k])\n",
    "        pre_at_n[k] = round(precision, 3)\n",
    "        rec_at_n[k] = round(recall, 3)\n",
    "    return pre_at_n, rec_at_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef691448-622c-4fd4-ad3c-1c71d25d21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_pre(ret_docs, reljudges, cutoff=-1):\n",
    "    \"\"\"\n",
    "    Calculate (mean) average precision for each query in ret_docs\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_pre, mean_avg_pre = {}, None\n",
    "    for k, v in ret_docs.items():\n",
    "        total_rel = 0\n",
    "        total = 0\n",
    "        avg_prec = 0\n",
    "        for i, doc in enumerate(v):\n",
    "            if doc in reljudges[k] and cutoff == -1:\n",
    "                total_rel += 1\n",
    "                total += 1\n",
    "                precision = total_rel/total\n",
    "            elif doc in reljudges[k] and i+1 <= cutoff:\n",
    "                total_rel += 1\n",
    "                total += 1\n",
    "                precision = total_rel/total\n",
    "            else:\n",
    "                total += 1\n",
    "                precision = 0\n",
    "            avg_prec += precision\n",
    "\n",
    "        avg_pre[k] = round(avg_prec/len(reljudges[k]), 3,)\n",
    "    \n",
    "    mean_avg_pre = round(sum(avg_pre.values()) / len(avg_pre), 3)\n",
    "        \n",
    "    return avg_pre, mean_avg_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02afa9c6-f5a2-495d-87ae-aebae7d9cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_NDCG_at_n(ret_docs, reljudges, n=-1, base=2):\n",
    "    \"\"\"\n",
    "    Calculate NDCG at n for each query in ret_docs\n",
    "    \"\"\"\n",
    "    \n",
    "    ndcg = {}\n",
    "    \n",
    "    for k, v in ret_docs.items():\n",
    "        \n",
    "        counts = list(reversed([x for x in range(2,len(reljudges[k])+2)]))\n",
    "        ideals = {reljudges[k][i]: counts[i] for i in range(len(reljudges[k]))}\n",
    "        \n",
    "        add_ons = {}\n",
    "        if len(v) > len(reljudges[k]):\n",
    "            for i in range(len(v)-len(reljudges[k])):\n",
    "                add_ons[i] = 1\n",
    "        ideals.update(add_ons)\n",
    "        nums = list(map(ideals.get, v))\n",
    "        \n",
    "        systems = {}\n",
    "        for i, doc in enumerate(v):\n",
    "            if nums[i] == None:\n",
    "                systems[doc] = 1\n",
    "            else:\n",
    "                systems[doc] = nums[i]\n",
    "                \n",
    "        ideal_order = {}\n",
    "        if n != -1:\n",
    "            for i, (key, value) in enumerate(ideals.items()):\n",
    "                if i < n:\n",
    "                    ideal_order[key] = value\n",
    "        else:\n",
    "            ideal_order = ideals\n",
    "        \n",
    "        add_ons = {}\n",
    "        \n",
    "        \n",
    "        log = 0\n",
    "        for i, (doc, rank) in enumerate(ideal_order.items()):\n",
    "            if i >= len(v):\n",
    "                break\n",
    "            elif i < base:\n",
    "                log += rank\n",
    "            else:\n",
    "                log += rank/math.log(i+1, base)\n",
    "\n",
    "                \n",
    "        system_order = {}\n",
    "        if n != -1:\n",
    "            for i, (key, value) in enumerate(systems.items()):\n",
    "                if i < n:\n",
    "                    system_order[key] = value\n",
    "        else:\n",
    "            system_order = systems\n",
    "        \n",
    "        \n",
    "        \n",
    "        system_log = 0\n",
    "        for i, (doc, rank) in enumerate(system_order.items()):\n",
    "            if i >= len(v):\n",
    "                break\n",
    "            elif i < base:\n",
    "                system_log += rank\n",
    "            else:\n",
    "                system_log += rank/math.log(i+1, base)\n",
    "        system_log / log\n",
    "        ndcg[k] = round(system_log / log, 3)\n",
    "        \n",
    "    \n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fe45a-8fdb-4404-bb8d-4f401fa67694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_docs_dic = {}\n",
    "queries_dic = {}\n",
    "\n",
    "for query in relevant_naics.iterrows():\n",
    "    query_name =  ' '.join(process_query(query[1]['query'], 'lemmatize'))\n",
    "    ret_docs_index = lsi_model.retrieve_docs(query_name, max_docs=max_docs, normalization='lemmatize')\n",
    "    ret_docs = df.iloc[ret_docs_index]['naics'].tolist()\n",
    "\n",
    "    query_docs = query[1]['relevant_naics']\n",
    "    ret_docs_dic[query_name] = ret_docs\n",
    "    queries_dic[query_name] = query_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6391417-0b44-419c-b77d-8b8b8a4dab0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret_docs_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9b8a1-c91e-492f-b760-0363d1d77994",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330f82c-c782-44b9-bf02-b3eaa0fdb8f7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_pre_rec_at_n(ret_docs_dic, queries_dic, n=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7622226-8609-4af4-9ffa-2e92177aaa28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_pre_rec_at_n(ret_docs_dic, queries_dic, n=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed729345-fd11-4cb5-9abf-6479902e4ae1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_avg_pre(ret_docs_dic, queries_dic, cutoff=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b9e50-eb0c-40cf-83f3-80fb003ac61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmmatizing performs a bit better in the concept space, perhaps because full words group into concepts al ittle differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52ce24-6f8d-40bd-83ad-5ac5b46d7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_avg_pre(ret_docs_dic, queries_dic, cutoff=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a123e4d-b48a-4b77-a158-c6db32753a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_maps = []\n",
    "for i in range(1, 11):\n",
    "    lsi_maps.append(calc_avg_pre(ret_docs_dic, queries_dic, cutoff=i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18941dd7-c11d-4cb7-9c25-83ceef3667c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a6cc7-c3a0-469c-9f08-8fac91221985",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_NDCG_at_n(ret_docs_dic, queries_dic, n=-1, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d746004-ea75-4a3a-bbec-3f4295921d03",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde2032-59ce-409e-a455-cbdf5d41af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = dict(zip(df['naics'], df['stemmed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b72529-b560-4a4e-9b67-0fb8f4ada7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LsiTfidfRecommenderSystem(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f3299-413a-4805-a72b-6722c4fc4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_docs_dic = {}\n",
    "queries_dic = {}\n",
    "\n",
    "for query in relevant_naics.iterrows():\n",
    "    query_name =  ' '.join(process_query(query[1]['query'], 'stem'))\n",
    "    ret_docs_index = lsi_model.retrieve_docs(query_name, max_docs=max_docs, normalization='stem')\n",
    "    ret_docs = df.iloc[ret_docs_index]['naics'].tolist()\n",
    "\n",
    "    query_docs = query[1]['relevant_naics']\n",
    "    ret_docs_dic[query_name] = ret_docs\n",
    "    queries_dic[query_name] = query_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194e34a-ec40-4110-ac46-8be4d87b451f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_pre_rec_at_n(ret_docs_dic, queries_dic, n=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5ed9a-1e53-480f-97d7-6b2b430177a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_pre_rec_at_n(ret_docs_dic, queries_dic, n=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47ee95-c4fc-420b-a94b-f50dd002e051",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_avg_pre(ret_docs_dic, queries_dic, cutoff=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f3cdf-f686-4a7b-8beb-77c853a8e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_avg_pre(ret_docs_dic, queries_dic, cutoff=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912513bb-f0e7-4d56-ba66-bf7b29008a66",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_NDCG_at_n(ret_docs_dic, queries_dic, n=-1, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f63391-6b94-4365-897a-474f18621250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'assets/processed_df.pkl')\n",
    "docs = dict(zip(df['naics'], df['lemmatized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea902f-6b2d-4b61-ae97-1cdf8a88dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [5, 10, 20, 50, 100, 150, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ca03a-46c4-4c5c-bcf3-8d0f54a66b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in concepts:\n",
    "    lsi_model = LsiTfidfRecommenderSystem(docs, num_concepts=concept)\n",
    "    ret_docs_dic = {}\n",
    "    queries_dic = {}\n",
    "\n",
    "    for query in relevant_naics.iterrows():\n",
    "        query_name =  ' '.join(process_query(query[1]['query'], 'lemmatize'))\n",
    "        ret_docs_index = lsi_model.retrieve_docs(query_name, max_docs=max_docs)\n",
    "        ret_docs = df.iloc[ret_docs_index]['naics'].tolist()\n",
    "\n",
    "        query_docs = query[1]['relevant_naics']\n",
    "        ret_docs_dic[query_name] = ret_docs\n",
    "        queries_dic[query_name] = query_docs\n",
    "    print(f'Number of concepts: {concept} ' + str(calc_avg_pre(ret_docs_dic, queries_dic, cutoff=-1)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
