{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505b49c1-51ea-4054-81eb-313e098146ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a352da46-1757-4c7a-b37e-dc88f688e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\\\\b\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers (punctuation, curly brackets etc).\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    # replace the matched string with ' '\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(description, stop_words, normalization):\n",
    "    \n",
    "    if normalization == 'lemmatize':\n",
    "        # tokenize and lemmatize text\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(w) for w in word_tokenize(description)]\n",
    "        \n",
    "    elif normalization == 'stem':\n",
    "        # tokenize and stem text\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(w) for w in word_tokenize(description)]\n",
    "    \n",
    "   # remove tokens length of 2 or below and make all lowercase and remove stop words\n",
    "    tokens = [w.lower() for w in tokens if (w.lower() not in stop_words) and (len(w) > 2) and(w.isalpha())]\n",
    "    \n",
    "    return tokens    \n",
    "    \n",
    "def process_query(query, normalization):\n",
    "    \n",
    "    return tokenizer(clean_text(query), stop_words, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec43a45-bfe8-4c34-a561-90d5f42345e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code example taken from https://towardsdatascience.com/build-a-text-recommendation-system-with-python-e8b95d9f251c\n",
    "def retrieve_top_n(m, max_docs):\n",
    "    # return the sum on all tokens of cosinus for each sentence\n",
    "    if len(m.shape) > 1:\n",
    "        cos_sim = np.mean(m, axis=0) \n",
    "    else: \n",
    "        cos_sim = m\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \\\n",
    "    mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:max_docs]  \n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c4d3fb-5e2e-4c72-b295-b9e42e4437db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfRecommenderSystem:\n",
    "    def __init__(self, docs, num_concepts=100, min_df=1, alpha=1.0, beta=0.75, gamma=0.15):\n",
    "        self.alpha, self.beta, self.gamma = alpha, beta, gamma\n",
    "        \n",
    "        # create a doc-term matrix out of our doc collection\n",
    "        self.vec = TfidfVectorizer()\n",
    "        doc_term_mat = self.vec.fit_transform([\" \".join(docs[doc_id]) for doc_id in docs])\n",
    "        result = doc_term_mat\n",
    "        \n",
    "        self.q_vecs = {}\n",
    "        \n",
    "        self.doc_vecs = result # document vectors in a matrix\n",
    "        \n",
    "    def retrieve_docs(self, query, max_docs=10):\n",
    "        query = ' '.join(process_query(query, 'lemmatize'))\n",
    "        \n",
    "        if query not in self.q_vecs:\n",
    "            q_vec = self.vec.transform([query])\n",
    "            self.q_vecs[query] = q_vec\n",
    "        \n",
    "        ret_docs = {}\n",
    "        \n",
    "        mat = cosine_similarity(self.q_vecs[query], self.doc_vecs)\n",
    "        best_index = retrieve_top_n(mat, max_docs=max_docs)\n",
    "        \n",
    "        return best_index\n",
    "    \n",
    "    def gather_feedback(self, query, max_docs=10, feedback=None):\n",
    "        \"\"\"\n",
    "        This function models the interactive relevance feedback loop\n",
    "        \"\"\"\n",
    "        query = ' '.join(process_query(query, 'lemmatize'))\n",
    "        # Step 2: Retrieve the required number of docs in reponse to the queries\n",
    "        ret_docs = self.retrieve_docs(query, max_docs=max_docs)\n",
    "        \n",
    "        \n",
    "        # display docs to user\n",
    "        # receive feedback from user\n",
    "\n",
    "        # Step 3: Obtain feedback from the user in the form of precisions at each rank\n",
    "        user_feedback = feedback\n",
    "        # map index to user feedback\n",
    "        idx_dic = {}\n",
    "        \n",
    "        for i, doc in enumerate(ret_docs):\n",
    "            try:\n",
    "                idx_dic[doc] = user_feedback[i]\n",
    "            except:\n",
    "                idx_dic[doc] = 0\n",
    "\n",
    "        self.q_vecs[query] = np.dot(self.alpha, self.q_vecs[query])\n",
    "        for key, value in idx_dic.items():\n",
    "            if value == 1:\n",
    "                self.q_vecs[query] += np.dot(self.beta, self.doc_vecs[key])\n",
    "            else:\n",
    "                self.q_vecs[query] -= np.dot(self.gamma, self.doc_vecs[key])\n",
    "        self.q_vecs[query][self.q_vecs[query] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b803483-746f-4309-9d39-6ce3e2328b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'assets/processed_df.pkl')\n",
    "docs = dict(zip(df['naics'], df['lemmatized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c31a287-1569-48e5-8612-6d4fd1380828",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfRecommenderSystem(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f648978-c31c-4aef-86bb-7c89dcb67c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = tfidf_model.retrieve_docs('Home improvement store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbc5064c-7a73-4ea7-99a0-0a295d172842",
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_titles = pd.read_excel('assets/6-digit_2017_Codes.xlsx')\n",
    "naics_titles['naics'] = naics_titles['naics'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa1e103-9ee1-4900-bbec-91b664c53148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(naics_titles, on='naics', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e95f4046-85eb-4666-b813-6dbbe1180465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>442299</td>\n",
       "      <td>Bath shops All Other Home Furnishings Stores  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>453998</td>\n",
       "      <td>Architectural supply stores All Other Miscella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>453991</td>\n",
       "      <td>Cigar stores Tobacco Stores  This U S  industr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>442291</td>\n",
       "      <td>Curtain and drapery stores  packaged Window Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>453930</td>\n",
       "      <td>Manufactured  mobile  home dealers Manufacture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>453910</td>\n",
       "      <td>Feed stores  pet Pet and Pet Supplies Stores  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>453920</td>\n",
       "      <td>Art auctions Art Dealers  This industry compri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>453310</td>\n",
       "      <td>Antique dealers  except motor vehicles  Used M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>445299</td>\n",
       "      <td>Coffee and tea  i e   packaged  stores All Oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>444110</td>\n",
       "      <td>Home centers  building materials Home Centers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      naics                                        description\n",
       "578  442299  Bath shops All Other Home Furnishings Stores  ...\n",
       "629  453998  Architectural supply stores All Other Miscella...\n",
       "628  453991  Cigar stores Tobacco Stores  This U S  industr...\n",
       "577  442291  Curtain and drapery stores  packaged Window Tr...\n",
       "627  453930  Manufactured  mobile  home dealers Manufacture...\n",
       "625  453910  Feed stores  pet Pet and Pet Supplies Stores  ...\n",
       "626  453920  Art auctions Art Dealers  This industry compri...\n",
       "624  453310  Antique dealers  except motor vehicles  Used M...\n",
       "594  445299  Coffee and tea  i e   packaged  stores All Oth...\n",
       "581  444110  Home centers  building materials Home Centers ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[best_index][['naics', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641ce74-af86-45fe-93f3-bd12dd34f3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
